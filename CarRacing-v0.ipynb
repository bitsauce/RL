{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from skimage import transform\n",
    "from IPython.display import display, clear_output\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import FrameStack, Scheduler, calculate_expected_return\n",
    "from a2c import GaussianA2C\n",
    "from vec_env.subproc_vec_env import SubprocVecEnv\n",
    "\n",
    "lr_scheduler = Scheduler(initial_value=1e-4, interval=10, decay_factor=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Env():\n",
    "    def __init__(self):\n",
    "        self.env = gym.make(\"CarRacing-v0\")\n",
    "        self.action_space = self.env.action_space.shape[0]\n",
    "        self.state_space  = (*self.env.observation_space.shape[0:2], 4)\n",
    "        \n",
    "    def reset(self):\n",
    "        initial_frame = self.env.reset()\n",
    "        def preprocess_frame(frame):\n",
    "            frame = np.dot(frame[..., 0:3], [0.299, 0.587, 0.114])\n",
    "            frame = frame / 255.0\n",
    "            return frame\n",
    "        self.frame_stack = FrameStack(initial_frame, preprocess_fn=preprocess_frame)\n",
    "        self.done = False\n",
    "        \n",
    "    def step(self, action):\n",
    "        if self.done:\n",
    "            return 0\n",
    "        frame, reward, done, info = self.env.step(action)\n",
    "        self.frame_stack.add_frame(frame)\n",
    "        self.done = done\n",
    "        self.env.render()\n",
    "        return reward\n",
    "    \n",
    "    def is_done(self):\n",
    "        return self.done\n",
    "    \n",
    "    def get_state(self):\n",
    "        return self.frame_stack.get_state()\n",
    "        \n",
    "def preprocess_frame(frame):\n",
    "    frame = np.dot(frame[..., 0:3], [0.299, 0.587, 0.114])\n",
    "    frame = frame / 255.0\n",
    "    return frame\n",
    "\n",
    "def make_env():\n",
    "    return gym.make(\"CarRacing-v0\")\n",
    "\n",
    "num_envs = 8\n",
    "envs = SubprocVecEnv([make_env for _ in range(num_envs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discount_factor  = 0.99\n",
    "save_interval    = 100\n",
    "t_max            = 5\n",
    "frame_stack_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Episode 2 --\n",
      "Learning rate: 0.0001\n",
      "Episode policy loss: -64.99564262060449\n",
      "Episode value loss: 141.3993214443326\n",
      "Episode entropy loss: 914.8210849761963\n",
      "Episode loss: -3.4441928304731846\n",
      "Average episode reward: -36.83904776283194\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni3CsAeIiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2266f905550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting envronments...\n",
      "Training...\n"
     ]
    }
   ],
   "source": [
    "input_shape = (*envs.observation_space.shape[0:2], 4)\n",
    "a2c_model = GaussianA2C(envs.action_space.shape[0], input_shape, tf.train.RMSPropOptimizer,\n",
    "                        value_scale=0.5, entropy_scale=0.01, model_checkpoint=None, model_name=\"CarRacing-v0\")\n",
    "\n",
    "average_episode_rewards = []\n",
    "episode = 0\n",
    "while True:\n",
    "    print(\"Resetting envronments...\")\n",
    "    episode += 1\n",
    "    initial_frames = envs.reset()\n",
    "    frame_stacks = [FrameStack(initial_frames[i], preprocess_fn=preprocess_frame) for i in range(num_envs)]\n",
    "    dones = [False] * num_envs\n",
    "    \n",
    "    # While there are running environments\n",
    "    print(\"Training...\")\n",
    "    learning_rate = lr_scheduler.get_value()\n",
    "    total_reward = 0\n",
    "    episode_loss = episode_policy_loss = episode_value_loss = episode_entropy_loss = 0\n",
    "    average_episode_reward = []\n",
    "    while sum(dones) < num_envs:\n",
    "        states_mb, actions_mb, returns_mb, values_mb = [], [], [], []\n",
    "        \n",
    "        # Simulate game for some number of steps\n",
    "        rewards_mb = []\n",
    "        for _ in range(t_max):\n",
    "            # Predict and value action given state\n",
    "            # π(a_t | s_t; θ)\n",
    "            states = [frame_stacks[i].get_state() if dones[i] == False else np.zeros(input_shape) for i in range(num_envs)]\n",
    "            actions_mean, actions_variance, values = a2c_model.predict(states)\n",
    "\n",
    "            # Sample action from a Gaussian distribution\n",
    "            actions = np.random.normal(loc=actions_mean, scale=np.sqrt(actions_variance))\n",
    "            envs.step_async(actions)\n",
    "            frames, rewards, dones, infos = envs.step_wait()\n",
    "            \n",
    "            # Store state, action and reward\n",
    "            states_mb.extend(states)\n",
    "            actions_mb.extend(actions)\n",
    "            rewards_mb.extend(rewards)\n",
    "            values_mb.extend(np.squeeze(values, axis=-1))\n",
    "            total_reward += np.sum(rewards)\n",
    "            \n",
    "            # Get new state\n",
    "            for i in range(num_envs):\n",
    "                frame_stacks[i].add_frame(frames[i])\n",
    "\n",
    "        # Calculate return (discounted rewards over a trajectory)\n",
    "        states = [frame_stacks[i].get_state() if dones[i] == False else np.zeros(input_shape) for i in range(num_envs)]\n",
    "        last_values = a2c_model.predict(states)[-1]\n",
    "        for i in range(num_envs):\n",
    "            if dones[i] == False:\n",
    "                returns_mb.extend(calculate_expected_return(rewards_mb[i::num_envs]+[last_values[i]], discount_factor)[:-1])\n",
    "            else:\n",
    "                returns_mb.extend(calculate_expected_return(rewards_mb[i::num_envs]+[0], discount_factor)[:-1])\n",
    "\n",
    "        eploss, pgloss, vloss, entloss = a2c_model.train(states_mb, actions_mb, np.squeeze(returns_mb, axis=-1), values_mb, learning_rate=learning_rate)\n",
    "        episode_loss         += eploss\n",
    "        episode_policy_loss  += pgloss\n",
    "        episode_value_loss   += vloss\n",
    "        episode_entropy_loss += entloss\n",
    "    average_episode_rewards.append(total_reward / num_envs)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print(\"-- Episode {} --\".format(episode))\n",
    "    print(\"Learning rate:\", learning_rate)\n",
    "    print(\"Episode policy loss:\", episode_policy_loss)\n",
    "    print(\"Episode value loss:\", episode_value_loss)\n",
    "    print(\"Episode entropy loss:\", episode_entropy_loss)\n",
    "    print(\"Episode loss:\", episode_loss)\n",
    "    print(\"Average episode reward:\", average_episode_rewards[-1])\n",
    "    print(\"\")\n",
    "    plt.plot(np.arange(0, len(average_episode_rewards)), average_episode_rewards)\n",
    "    plt.show()\n",
    "    \n",
    "    if episode % save_interval == 0:\n",
    "        a2c_model.save()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.array(rewards_mb[::num_envs]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "env = DoomEnv(True)\n",
    "greedy = True\n",
    "for episode in range(10):\n",
    "    env.reset()\n",
    "    while not env.game.is_episode_finished():\n",
    "        # Predict action given state: π(a_t | s_t; θ)\n",
    "        action_prob = np.squeeze(a2c_model.predict(np.expand_dims(env.state, axis=0))[0])\n",
    "        if greedy:\n",
    "            action = np.argmax(action_prob)\n",
    "        else:\n",
    "            action = np.random.choice(np.arange(0, num_actions), p=action_prob) # Sample action stochastically\n",
    "        action_one_hot = [False] * num_actions\n",
    "        action_one_hot[action] = True\n",
    "\n",
    "        # Take the action\n",
    "        env.game.make_action(action_one_hot)\n",
    "        time.sleep(0.016)\n",
    "        \n",
    "        if not env.game.is_episode_finished():\n",
    "            # Get new state\n",
    "            env.frame_stack.append(preprocess_frame(env.game.get_state().screen_buffer))\n",
    "            env.state = np.stack(env.frame_stack, axis=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
