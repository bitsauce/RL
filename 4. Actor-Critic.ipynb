{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import vizdoom\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from skimage import transform\n",
    "from IPython.display import display, clear_output\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Scheduler():\n",
    "    def __init__(self, initial_value, interval, decay_factor):\n",
    "        self.interval = self.counter = interval\n",
    "        self.decay_factor = decay_factor\n",
    "        self.value_factor = 1\n",
    "        self.value = initial_value\n",
    "        \n",
    "    def get_value(self):\n",
    "        self.counter -= 1\n",
    "        if self.counter < 0:\n",
    "            self.counter = self.interval\n",
    "            self.value *= self.decay_factor\n",
    "        return self.value\n",
    "        \n",
    "lr_scheduler = Scheduler(initial_value=1e-4, interval=10, decay_factor=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DoomEnv():\n",
    "    def __init__(self, show_window=False):\n",
    "        # Setup DoomGame\n",
    "        self.game = vizdoom.DoomGame()\n",
    "        #self.game.load_config(\"doom/my_way_home.cfg\")\n",
    "        #self.game.load_config(\"doom/defend_the_center.cfg\")\n",
    "        self.game.load_config(\"doom/basic.cfg\")\n",
    "\n",
    "        # Visualize the game (set to False to train faster)\n",
    "        self.game.set_window_visible(show_window)\n",
    "\n",
    "        # Set screen format to greyscale, improves training time\n",
    "        self.game.set_screen_format(vizdoom.ScreenFormat.GRAY8)\n",
    "\n",
    "        # Make the game end after 2100 ticks (set to 0 to disable)\n",
    "        #self.game.set_episode_timeout(2100)\n",
    "\n",
    "        # Init game\n",
    "        self.game.init()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.game.new_episode()\n",
    "        \n",
    "        # Setup initial state\n",
    "        self.frame_stack = deque(maxlen=frame_stack_size)\n",
    "        initial_frame = preprocess_frame(self.game.get_state().screen_buffer)\n",
    "        for _ in range(frame_stack_size):\n",
    "            self.frame_stack.append(initial_frame)\n",
    "        self.state = np.stack(self.frame_stack, axis=2)\n",
    "        \n",
    "        self.total_reward = 0\n",
    "        \n",
    "num_envs = 16\n",
    "envs = [DoomEnv(i == 0) for i in range(num_envs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discount_factor  = 0.99\n",
    "num_actions      = envs[0].game.get_available_buttons_size()\n",
    "save_interval    = 100\n",
    "t_max            = 5\n",
    "frame_stack_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(logits):\n",
    "    a0 = logits - tf.reduce_max(logits, axis=-1, keepdims=True)\n",
    "    ea0 = tf.exp(a0)\n",
    "    z0 = tf.reduce_sum(ea0, axis=-1, keepdims=True)\n",
    "    p0 = ea0 / z0\n",
    "    return tf.reduce_sum(p0 * (tf.log(z0) - a0), axis=-1)\n",
    "\n",
    "class A2C():\n",
    "    def __init__(self, num_actions, optimizer, value_scale=0.5, entropy_scale=0.01, model_checkpoint=None):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        # Construct model\n",
    "        self.input_states = tf.placeholder(shape=(None, 84, 84, 4), dtype=tf.float32)\n",
    "        self.conv1 = tf.keras.layers.Conv2D(16, (5, 5), activation=\"relu\", padding=\"valid\")(self.input_states)\n",
    "        self.pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(self.conv1)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"valid\")(self.pool1)\n",
    "        self.pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(self.conv2)\n",
    "        self.conv3 = tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"valid\")(self.pool2)\n",
    "        self.shared_features = tf.keras.layers.Flatten()(self.conv3)\n",
    "        \n",
    "        # Policy branch\n",
    "        self.action_logits = tf.keras.layers.Dense(num_actions, activation=None)(self.shared_features)\n",
    "        self.action_prob   = tf.keras.layers.Softmax()(self.action_logits)\n",
    "        \n",
    "        # Baseline value branch\n",
    "        self.value  = tf.keras.layers.Dense(1, activation=None)(self.shared_features) # V(s_t; θ_v)\n",
    "        \n",
    "        # Create policy gradient train function\n",
    "        self.actions_placeholder = tf.placeholder(shape=(None,), dtype=tf.int32)\n",
    "        self.returns_placeholder = tf.placeholder(shape=(None,), dtype=tf.float32)\n",
    "        self.values_placeholder  = tf.placeholder(shape=(None,), dtype=tf.float32)\n",
    "        self.lr_placeholder      = tf.placeholder(shape=(), dtype=tf.float32)\n",
    "        \n",
    "        # Get probabilities of taken actions: log π(a_t | s_t; θ)\n",
    "        # log_action_prob = tf.log(tf.reduce_sum(self.action_prob * self.actions_onehot_placeholder, axis=1))\n",
    "        self.neg_log_action = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.action_logits,\n",
    "                                                                             labels=self.actions_placeholder)\n",
    "        \n",
    "        # Policy Gradient Loss = ∇_θ log π(a_t | s_t; θ)(R_t − V(s_t; θ_v))\n",
    "        # Negative log likelihood of the taken actions, weighted by the discounted and normalized rewards\n",
    "        # self.policy_loss = -tf.reduce_mean(log_action_prob * (self.returns_placeholder - self.value))\n",
    "        self.policy_loss  = tf.reduce_mean((self.returns_placeholder - self.values_placeholder) * self.neg_log_action)\n",
    "        \n",
    "        # Get value loss\n",
    "        # MSE(V(s_t), R_t)\n",
    "        self.value_loss = tf.reduce_mean(tf.squared_difference(tf.squeeze(self.value), self.returns_placeholder))\n",
    "        \n",
    "        # Get entropy\n",
    "        # self.entropy_loss = -tf.reduce_mean(self.action_prob * tf.log(self.action_prob + 0.0001))\n",
    "        self.entropy_loss = tf.reduce_mean(entropy(self.action_logits))\n",
    "        \n",
    "        # Total loss\n",
    "        self.loss = self.policy_loss + self.value_loss * value_scale - self.entropy_loss * entropy_scale\n",
    "        \n",
    "        # Minimize loss\n",
    "        self.optimizer = optimizer(learning_rate=self.lr_placeholder, decay=0.99)\n",
    "        self.learning_rate = 1e-4\n",
    "        self.train_step = self.optimizer.minimize(self.loss)\n",
    "        \n",
    "        # Create session\n",
    "        self.sess = tf.Session()\n",
    "\n",
    "        # Run the initializer\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        tf.summary.scalar(\"policy_loss\", self.policy_loss)\n",
    "        tf.summary.scalar(\"value_loss\", self.value_loss)\n",
    "        tf.summary.scalar(\"entropy_loss\", self.entropy_loss)\n",
    "        tf.summary.scalar(\"loss\", self.loss)\n",
    "        tf.summary.scalar(\"learning_rate\", self.lr_placeholder)\n",
    "        self.summary_merged = tf.summary.merge_all()\n",
    "        \n",
    "        # Load model checkpoint if provided\n",
    "        self.saver = tf.train.Saver()\n",
    "        if model_checkpoint:\n",
    "            self.run_idx = int(re.findall(r\"_run\\d+\", model_checkpoint)[0][len(\"_run\"):])\n",
    "            self.step_idx = int(re.findall(r\"_step\\d+\", model_checkpoint)[0][len(\"_step\"):])\n",
    "            self.saver.restore(self.sess, model_checkpoint)\n",
    "            print(\"Model checkpoint restored from {}\".format(model_checkpoint))\n",
    "        else:\n",
    "            self.run_idx = 0\n",
    "            while os.path.isdir(\"./logs/run{}\".format(self.run_idx)):\n",
    "                self.run_idx += 1\n",
    "            self.step_idx = 0\n",
    "        self.train_writer = tf.summary.FileWriter(\"./logs/run{}\".format(self.run_idx), self.sess.graph)\n",
    "        \n",
    "        \n",
    "    def save(self):\n",
    "        model_checkpoint = \"./models/a2c_run{}_step{}.ckpt\".format(self.run_idx, self.step_idx)\n",
    "        self.saver.save(self.sess, model_checkpoint)\n",
    "        print(\"Model checkpoint saved to {}\".format(model_checkpoint))\n",
    "        \n",
    "    def train(self, input_states, actions, returns, values):\n",
    "        r = self.sess.run([self.summary_merged, self.train_step, self.loss, self.policy_loss, self.value_loss, self.entropy_loss],\n",
    "                          feed_dict={self.input_states: input_states,\n",
    "                                     self.actions_placeholder: actions,\n",
    "                                     self.returns_placeholder: returns,\n",
    "                                     self.values_placeholder: values,\n",
    "                                     self.lr_placeholder: self.learning_rate})\n",
    "        self.train_writer.add_summary(r[0], self.step_idx)\n",
    "        self.step_idx += 1\n",
    "        return r[2:]\n",
    "        \n",
    "    def predict(self, input_states):\n",
    "        return self.sess.run([self.action_prob, self.value], feed_dict={self.input_states: input_states})\n",
    "    \n",
    "a2c_model = A2C(num_actions=num_actions, optimizer=tf.train.RMSPropOptimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Episode 1201 --\n",
      "Learning rate: 3.7314100463728023e-07\n",
      "Episode policy loss: -0.011631995148491114\n",
      "Episode value loss: 0.0030090386972005945\n",
      "Episode entropy loss: 23.818559050559998\n",
      "Episode loss: -0.2483130618929863\n",
      "Average episode reward: 0.05424999999999995\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ba056fdba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting envronments...\n",
      "Training...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0b5f08c7692e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[1;31m# Predict and value action given state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[1;31m# π(a_t | s_t; θ)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0maction_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma2c_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                 \u001b[0maction_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-d38af9e96811>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_states)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_states\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minput_states\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0ma2c_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA2C\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_actions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_actions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRMSPropOptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def preprocess_frame(frame):\n",
    "    cropped_frame = frame[30:-10, 30:-30] # Crop the screen\n",
    "    normalized_frame = cropped_frame / 255.0 # Normalize Pixel Values\n",
    "    preprocessed_frame = transform.resize(normalized_frame, [84, 84]) # Resize\n",
    "    return preprocessed_frame\n",
    "\n",
    "def calculate_expected_return(rewards, gamma):\n",
    "    expected_return = []\n",
    "    r = 0\n",
    "    for reward in rewards[::-1]: # for rewards from end to start\n",
    "        r = reward + gamma * r\n",
    "        expected_return.append(r)\n",
    "    return expected_return[::-1] # reverse so that we get the expected return from start to end\n",
    "\n",
    "average_episode_rewards = []\n",
    "#for episode in range(num_episodes):\n",
    "episode = 0\n",
    "while True:\n",
    "    print(\"Resetting envronments...\")\n",
    "    episode += 1\n",
    "    for env in envs:\n",
    "        env.reset()\n",
    "    \n",
    "    # While there are running environments\n",
    "    print(\"Training...\")\n",
    "    a2c_model.learning_rate = lr_scheduler.get_value()\n",
    "    episode_loss = episode_policy_loss = episode_value_loss = episode_entropy_loss = 0\n",
    "    average_episode_reward = []\n",
    "    while sum([env.game.is_episode_finished() for env in envs]) < num_envs:\n",
    "        states, actions, returns, values = [], [], [], []\n",
    "        \n",
    "        # For every environment\n",
    "        for env in envs:\n",
    "            # Simulate game for some number of steps\n",
    "            rewards = []\n",
    "            for _ in range(t_max):\n",
    "                # Predict and value action given state\n",
    "                # π(a_t | s_t; θ)\n",
    "                action_prob, value = a2c_model.predict(np.expand_dims(env.state, axis=0))\n",
    "                action_prob, value = np.squeeze(action_prob), np.squeeze(value)\n",
    "                \n",
    "                # Take action stochastically \n",
    "                action = np.random.choice(np.arange(0, num_actions), p=action_prob)\n",
    "                action_one_hot = [False] * num_actions\n",
    "                action_one_hot[action] = True\n",
    "                reward = env.game.make_action(action_one_hot) * 0.001\n",
    "                \n",
    "                # Store state, action and reward\n",
    "                states.append(env.state)\n",
    "                actions.append(action)\n",
    "                rewards.append(reward)\n",
    "                values.append(value)\n",
    "                env.total_reward += reward\n",
    "\n",
    "                if env.game.is_episode_finished():\n",
    "                    break\n",
    "                    \n",
    "                # Get new state\n",
    "                env.frame_stack.append(preprocess_frame(env.game.get_state().screen_buffer))\n",
    "                env.state = np.stack(env.frame_stack, axis=2)\n",
    "                \n",
    "            # Calculate return (discounted rewards over a trajectory)\n",
    "            last_value = 0 if env.game.is_episode_finished() else \\\n",
    "                         a2c_model.predict(np.expand_dims(env.state, axis=0))[1][0][0]\n",
    "            returns.extend(calculate_expected_return(rewards+[last_value], discount_factor)[:-1])\n",
    "            average_episode_reward.extend(rewards)\n",
    "            \n",
    "        eploss, pgloss, vloss, entloss = a2c_model.train(states, actions, returns, values)\n",
    "        episode_loss         += eploss\n",
    "        episode_policy_loss  += pgloss\n",
    "        episode_value_loss   += vloss\n",
    "        episode_entropy_loss += entloss\n",
    "    average_episode_rewards.append(sum([env.total_reward for env in envs]) / len(envs))\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print(\"-- Episode {} --\".format(episode))\n",
    "    print(\"Learning rate:\", a2c_model.learning_rate)\n",
    "    print(\"Episode policy loss:\", episode_policy_loss)\n",
    "    print(\"Episode value loss:\", episode_value_loss)\n",
    "    print(\"Episode entropy loss:\", episode_entropy_loss)\n",
    "    print(\"Episode loss:\", episode_loss)\n",
    "    print(\"Average episode reward:\", average_episode_rewards[-1])\n",
    "    print(\"\")\n",
    "    plt.plot(np.arange(0, len(average_episode_rewards)), average_episode_rewards)\n",
    "    plt.show()\n",
    "    \n",
    "    if episode % save_interval == 0:\n",
    "        a2c_model.save()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "env = DoomEnv(True)\n",
    "greedy = True\n",
    "for episode in range(10):\n",
    "    env.reset()\n",
    "    while not env.game.is_episode_finished():\n",
    "        # Predict action given state: π(a_t | s_t; θ)\n",
    "        action_prob = np.squeeze(a2c_model.predict(np.expand_dims(env.state, axis=0))[0])\n",
    "        if greedy:\n",
    "            action = np.argmax(action_prob)\n",
    "        else:\n",
    "            action = np.random.choice(np.arange(0, num_actions), p=action_prob) # Sample action stochastically\n",
    "        action_one_hot = [False] * num_actions\n",
    "        action_one_hot[action] = True\n",
    "\n",
    "        # Take the action\n",
    "        env.game.make_action(action_one_hot)\n",
    "        time.sleep(0.016)\n",
    "        \n",
    "        if not env.game.is_episode_finished():\n",
    "            # Get new state\n",
    "            env.frame_stack.append(preprocess_frame(env.game.get_state().screen_buffer))\n",
    "            env.state = np.stack(env.frame_stack, axis=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
