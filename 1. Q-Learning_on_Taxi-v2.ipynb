{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space: 6\n",
      "State Space: 500\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Taxi-v2')\n",
    "action_space = env.action_space.n\n",
    "state_space  = env.observation_space.n\n",
    "print(\"Action Space:\", action_space)\n",
    "print(\"State Space:\", state_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "Q_table = np.zeros((state_space, action_space))\n",
    "print(Q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Episode 0/50001 --\n",
      "Epsilon: 1.0\n",
      "Total reward: -370\n",
      "-- Episode 1000/50001 --\n",
      "Epsilon: 0.9800003999920002\n",
      "Total reward: -451\n",
      "-- Episode 2000/50001 --\n",
      "Epsilon: 0.9600007999840003\n",
      "Total reward: -334\n",
      "-- Episode 3000/50001 --\n",
      "Epsilon: 0.9400011999760005\n",
      "Total reward: -325\n",
      "-- Episode 4000/50001 --\n",
      "Epsilon: 0.9200015999680007\n",
      "Total reward: -388\n",
      "-- Episode 5000/50001 --\n",
      "Epsilon: 0.9000019999600009\n",
      "Total reward: -370\n",
      "-- Episode 6000/50001 --\n",
      "Epsilon: 0.8800023999520009\n",
      "Total reward: -370\n",
      "-- Episode 7000/50001 --\n",
      "Epsilon: 0.8600027999440011\n",
      "Total reward: -316\n",
      "-- Episode 8000/50001 --\n",
      "Epsilon: 0.8400031999360013\n",
      "Total reward: -361\n",
      "-- Episode 9000/50001 --\n",
      "Epsilon: 0.8200035999280014\n",
      "Total reward: -218\n",
      "-- Episode 10000/50001 --\n",
      "Epsilon: 0.8000039999200016\n",
      "Total reward: -370\n",
      "-- Episode 11000/50001 --\n",
      "Epsilon: 0.7800043999120018\n",
      "Total reward: -253\n",
      "-- Episode 12000/50001 --\n",
      "Epsilon: 0.7600047999040019\n",
      "Total reward: -214\n",
      "-- Episode 13000/50001 --\n",
      "Epsilon: 0.740005199896002\n",
      "Total reward: -307\n",
      "-- Episode 14000/50001 --\n",
      "Epsilon: 0.7200055998880022\n",
      "Total reward: -85\n",
      "-- Episode 15000/50001 --\n",
      "Epsilon: 0.7000059998800023\n",
      "Total reward: -307\n",
      "-- Episode 16000/50001 --\n",
      "Epsilon: 0.6800063998720025\n",
      "Total reward: -316\n",
      "-- Episode 17000/50001 --\n",
      "Epsilon: 0.6600067998640027\n",
      "Total reward: -68\n",
      "-- Episode 18000/50001 --\n",
      "Epsilon: 0.6400071998560029\n",
      "Total reward: -144\n",
      "-- Episode 19000/50001 --\n",
      "Epsilon: 0.620007599848003\n",
      "Total reward: -121\n",
      "-- Episode 20000/50001 --\n",
      "Epsilon: 0.6000079998400032\n",
      "Total reward: -68\n",
      "-- Episode 21000/50001 --\n",
      "Epsilon: 0.5800083998320034\n",
      "Total reward: -56\n",
      "-- Episode 22000/50001 --\n",
      "Epsilon: 0.5600087998240035\n",
      "Total reward: -65\n",
      "-- Episode 23000/50001 --\n",
      "Epsilon: 0.5400091998160037\n",
      "Total reward: -37\n",
      "-- Episode 24000/50001 --\n",
      "Epsilon: 0.5200095998080039\n",
      "Total reward: 3\n",
      "-- Episode 25000/50001 --\n",
      "Epsilon: 0.500009999800004\n",
      "Total reward: -19\n",
      "-- Episode 26000/50001 --\n",
      "Epsilon: 0.4800103997920041\n",
      "Total reward: -42\n",
      "-- Episode 27000/50001 --\n",
      "Epsilon: 0.4600107997840043\n",
      "Total reward: -95\n",
      "-- Episode 28000/50001 --\n",
      "Epsilon: 0.44001119977600445\n",
      "Total reward: -44\n",
      "-- Episode 29000/50001 --\n",
      "Epsilon: 0.4200115997680046\n",
      "Total reward: -44\n",
      "-- Episode 30000/50001 --\n",
      "Epsilon: 0.4000119997600048\n",
      "Total reward: -12\n",
      "-- Episode 31000/50001 --\n",
      "Epsilon: 0.38001239975200496\n",
      "Total reward: 7\n",
      "-- Episode 32000/50001 --\n",
      "Epsilon: 0.36001279974400513\n",
      "Total reward: -13\n",
      "-- Episode 33000/50001 --\n",
      "Epsilon: 0.3400131997360053\n",
      "Total reward: -41\n",
      "-- Episode 34000/50001 --\n",
      "Epsilon: 0.32001359972800547\n",
      "Total reward: 5\n",
      "-- Episode 35000/50001 --\n",
      "Epsilon: 0.30001399972000564\n",
      "Total reward: -18\n",
      "-- Episode 36000/50001 --\n",
      "Epsilon: 0.2800143997120058\n",
      "Total reward: -45\n",
      "-- Episode 37000/50001 --\n",
      "Epsilon: 0.2600147997040059\n",
      "Total reward: 8\n",
      "-- Episode 38000/50001 --\n",
      "Epsilon: 0.24001519969600604\n",
      "Total reward: 1\n",
      "-- Episode 39000/50001 --\n",
      "Epsilon: 0.2200155996880062\n",
      "Total reward: -8\n",
      "-- Episode 40000/50001 --\n",
      "Epsilon: 0.20001599968000638\n",
      "Total reward: -7\n",
      "-- Episode 41000/50001 --\n",
      "Epsilon: 0.18001639967200656\n",
      "Total reward: 3\n",
      "-- Episode 42000/50001 --\n",
      "Epsilon: 0.16001679966400673\n",
      "Total reward: 7\n",
      "-- Episode 43000/50001 --\n",
      "Epsilon: 0.1400171996560069\n",
      "Total reward: 5\n",
      "-- Episode 44000/50001 --\n",
      "Epsilon: 0.12001759964800707\n",
      "Total reward: -6\n",
      "-- Episode 45000/50001 --\n",
      "Epsilon: 0.10001799964000724\n",
      "Total reward: -26\n",
      "-- Episode 46000/50001 --\n",
      "Epsilon: 0.08001839963200741\n",
      "Total reward: 3\n",
      "-- Episode 47000/50001 --\n",
      "Epsilon: 0.06001879962400747\n",
      "Total reward: 10\n",
      "-- Episode 48000/50001 --\n",
      "Epsilon: 0.04001919961600764\n",
      "Total reward: 9\n",
      "-- Episode 49000/50001 --\n",
      "Epsilon: 0.02001959960800781\n",
      "Total reward: 7\n",
      "-- Episode 50000/50001 --\n",
      "Epsilon: 1.999960000798051e-05\n",
      "Total reward: 5\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 50001\n",
    "num_steps    = 100\n",
    "\n",
    "discount_rate = 0.7\n",
    "learning_rate = 0.1\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    print_info = episode % 1000 == 0\n",
    "    if print_info: print(\"-- Episode {}/{} --\".format(episode, num_episodes))\n",
    "    \n",
    "    epsilon = 1 - episode / num_episodes\n",
    "    total_reward = 0\n",
    "    \n",
    "    if print_info: print(\"Epsilon:\", epsilon)\n",
    "    \n",
    "    state = env.reset()\n",
    "    for step in range(num_steps):\n",
    "        if np.random.rand() > epsilon:\n",
    "            action = np.argmax(Q_table[state, :])\n",
    "        else:\n",
    "            action = np.random.randint(action_space)\n",
    "\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        # Q(s, a) <- Q(s, a) + alpha * [r + gamma * max_a' Q(s', a') - Q(s, a)]\n",
    "        Q_cur = Q_table[state, action]\n",
    "        Q_table[state, action] = Q_cur + learning_rate * (reward + discount_rate * np.max(Q_table[new_state, :]) - Q_cur)\n",
    "        \n",
    "        state = new_state\n",
    "        if done: break\n",
    "    if print_info: print(\"Total reward:\", total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : : : : |\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : : : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m| : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1m\u001b[43mY\u001b[0m\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[42mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "|\u001b[42m_\u001b[0m| : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : : : : |\n",
      "|\u001b[42m_\u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "|\u001b[42m_\u001b[0m: : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| :\u001b[42m_\u001b[0m: : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (East)\n",
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : :\u001b[42m_\u001b[0m: : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (East)\n",
      "+---------+\n",
      "|R: |\u001b[42m_\u001b[0m: :\u001b[35mG\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "+---------+\n",
      "|R: | :\u001b[42m_\u001b[0m:\u001b[35mG\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (East)\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[42mG\u001b[0m\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (East)\n",
      "Victory\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "for step in range(num_steps):\n",
    "    env.render()\n",
    "    action = np.argmax(Q_table[state, :])\n",
    "    new_state, reward, done, info = env.step(action)\n",
    "    state = new_state\n",
    "    if done:\n",
    "        print(\"Victory\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
